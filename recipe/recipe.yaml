schema_version: 1

context:
  name: llama-index-workflows
  version: "2.10.3"

package:
  name: ${{ name|lower }}
  version: ${{ version }}

source:
  url: https://pypi.org/packages/source/${{ name[0] }}/${{ name }}/llama_index_workflows-${{ version }}.tar.gz
  sha256: 3e9b21adf56f03d0c3e94eab3ac873f2914a8b31b721278d600eefebaed5ae2d

build:
  number: 0
  noarch: python
  script: ${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation

requirements:
  host:
    - python ${{ python_min }}.*
    - hatchling
    - pip
  run:
    - python >=${{ python_min }}
    - eval-type-backport >=0.2.2
    - llama-index-instrumentation >=0.1.0
    - pydantic >=2.11.5

tests:
  - python:
      imports:
        - workflows
      python_version: ${{ python_min }}.*
  - requirements:
      run:
        - pip
        - python ${{ python_min }}.*
    script:
      - pip check

about:
  summary: An event-driven, async-first, step-based way to control the execution flow of AI applications like Agents.
  license: MIT
  license_file: LICENSE
  homepage: https://github.com/run-llama/llama_index

extra:
  recipe-maintainers:
    - jan-janssen
